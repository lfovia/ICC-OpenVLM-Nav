# ICC-OpenVLM-Nav
Through this work we try to see the suitability of open VLM's like CLIP, BLIP and Qwen towards embodied navigation, without any pre training.

## Steps to set up repository

1. Clone the [PixNav](https://github.com/wzcai99/Pixel-Navigator) Repository by following the steps on their page
2. Within Pixel-Navigator directory clone [habitat-lab](https://github.com/facebookresearch/habitat-lab) and download MP3D dataset
3. Install dependcies like pytorch, transformers, numpy
4. Clone the files from our repository into Pixel-Navigator directory


